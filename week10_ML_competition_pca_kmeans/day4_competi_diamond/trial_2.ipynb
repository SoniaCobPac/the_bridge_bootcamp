{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       carat        cut color clarity  depth  table     x     y     z  price\n",
       "0       1.21      Ideal     H     VS2   63.0   57.0  6.73  6.70  4.23   6134\n",
       "1       0.28  Very Good     D    VVS2   64.0   56.0  4.14  4.17  2.66    532\n",
       "2       0.42    Premium     F     VS1   61.2   58.0  4.86  4.82  2.96   1103\n",
       "3       0.26      Ideal     H      IF   61.1   57.0  4.16  4.12  2.53    600\n",
       "4       1.10       Good     G     SI1   63.4   57.0  6.52  6.55  4.14   4997\n",
       "...      ...        ...   ...     ...    ...    ...   ...   ...   ...    ...\n",
       "40340   1.55    Premium     H     VS2   61.3   61.0  7.46  7.39  4.55  11708\n",
       "40341   0.36      Ideal     D     SI1   60.6   56.0  4.58  4.63  2.79    619\n",
       "40342   0.57  Very Good     I     VS2   62.2   55.0  5.33  5.34  3.32   1267\n",
       "40343   1.01  Very Good     F      IF   59.6   62.0  6.47  6.56  3.88   9965\n",
       "40344   0.54      Ideal     E     SI2   60.4   57.0  5.33  5.27  3.20   1340\n",
       "\n",
       "[40345 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.21</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>63.0</td>\n      <td>57.0</td>\n      <td>6.73</td>\n      <td>6.70</td>\n      <td>4.23</td>\n      <td>6134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.28</td>\n      <td>Very Good</td>\n      <td>D</td>\n      <td>VVS2</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>4.14</td>\n      <td>4.17</td>\n      <td>2.66</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>Premium</td>\n      <td>F</td>\n      <td>VS1</td>\n      <td>61.2</td>\n      <td>58.0</td>\n      <td>4.86</td>\n      <td>4.82</td>\n      <td>2.96</td>\n      <td>1103</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>IF</td>\n      <td>61.1</td>\n      <td>57.0</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>2.53</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.10</td>\n      <td>Good</td>\n      <td>G</td>\n      <td>SI1</td>\n      <td>63.4</td>\n      <td>57.0</td>\n      <td>6.52</td>\n      <td>6.55</td>\n      <td>4.14</td>\n      <td>4997</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40340</th>\n      <td>1.55</td>\n      <td>Premium</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>61.3</td>\n      <td>61.0</td>\n      <td>7.46</td>\n      <td>7.39</td>\n      <td>4.55</td>\n      <td>11708</td>\n    </tr>\n    <tr>\n      <th>40341</th>\n      <td>0.36</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>SI1</td>\n      <td>60.6</td>\n      <td>56.0</td>\n      <td>4.58</td>\n      <td>4.63</td>\n      <td>2.79</td>\n      <td>619</td>\n    </tr>\n    <tr>\n      <th>40342</th>\n      <td>0.57</td>\n      <td>Very Good</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.2</td>\n      <td>55.0</td>\n      <td>5.33</td>\n      <td>5.34</td>\n      <td>3.32</td>\n      <td>1267</td>\n    </tr>\n    <tr>\n      <th>40343</th>\n      <td>1.01</td>\n      <td>Very Good</td>\n      <td>F</td>\n      <td>IF</td>\n      <td>59.6</td>\n      <td>62.0</td>\n      <td>6.47</td>\n      <td>6.56</td>\n      <td>3.88</td>\n      <td>9965</td>\n    </tr>\n    <tr>\n      <th>40344</th>\n      <td>0.54</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>60.4</td>\n      <td>57.0</td>\n      <td>5.33</td>\n      <td>5.27</td>\n      <td>3.20</td>\n      <td>1340</td>\n    </tr>\n  </tbody>\n</table>\n<p>40345 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/diamonds_train.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 40345 entries, 0 to 40344\nData columns (total 10 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   carat    40345 non-null  float64\n 1   cut      40345 non-null  object \n 2   color    40345 non-null  object \n 3   clarity  40345 non-null  object \n 4   depth    40345 non-null  float64\n 5   table    40345 non-null  float64\n 6   x        40345 non-null  float64\n 7   y        40345 non-null  float64\n 8   z        40345 non-null  float64\n 9   price    40345 non-null  int64  \ndtypes: float64(6), int64(1), object(3)\nmemory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z  price\n",
       "0   1.21      Ideal     H     VS2   63.0   57.0  6.73  6.70  4.23   6134\n",
       "1   0.28  Very Good     D    VVS2   64.0   56.0  4.14  4.17  2.66    532\n",
       "2   0.42    Premium     F     VS1   61.2   58.0  4.86  4.82  2.96   1103\n",
       "3   0.26      Ideal     H      IF   61.1   57.0  4.16  4.12  2.53    600\n",
       "4   1.10       Good     G     SI1   63.4   57.0  6.52  6.55  4.14   4997"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.21</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>63.0</td>\n      <td>57.0</td>\n      <td>6.73</td>\n      <td>6.70</td>\n      <td>4.23</td>\n      <td>6134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.28</td>\n      <td>Very Good</td>\n      <td>D</td>\n      <td>VVS2</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>4.14</td>\n      <td>4.17</td>\n      <td>2.66</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>Premium</td>\n      <td>F</td>\n      <td>VS1</td>\n      <td>61.2</td>\n      <td>58.0</td>\n      <td>4.86</td>\n      <td>4.82</td>\n      <td>2.96</td>\n      <td>1103</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>IF</td>\n      <td>61.1</td>\n      <td>57.0</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>2.53</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.10</td>\n      <td>Good</td>\n      <td>G</td>\n      <td>SI1</td>\n      <td>63.4</td>\n      <td>57.0</td>\n      <td>6.52</td>\n      <td>6.55</td>\n      <td>4.14</td>\n      <td>4997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## 1. Data transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Cut property"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Ideal', 'Very Good', 'Premium', 'Good', 'Fair'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df[\"cut\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cut order from high to low is: Ideal, Premium, very good, good, fair\n",
    "# LabelEncoder assigns values by alphabetical order so instead a lambda is used to encode this column\n",
    "\n",
    "\n",
    "df[\"cut\"] = df[\"cut\"].replace({\"Ideal\": 5, \"Premium\": 4, \"Very Good\": 3, \"Good\": 2, \"Fair\": 1})"
   ]
  },
  {
   "source": [
    "### Color property"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['H', 'D', 'F', 'G', 'I', 'E', 'J'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A higher price is linked to the alphabetical order of the property 'color'. However, there is a big price difference beteween D and E, and F and G, so we'll increase the value difference between some colors before training the model\n",
    "\n",
    "df[\"color\"] = df[\"color\"].replace({\"D\": 7, \"E\": 6, \"F\": 5, \"G\": 4, \"H\": 3, \"I\":2, \"J\":1})"
   ]
  },
  {
   "source": [
    "### clarity "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['VS2', 'VVS2', 'VS1', 'IF', 'SI1', 'SI2', 'VVS1', 'I1'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df[\"clarity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order considering a higer to lower price: IF, VVS1, VVS2, VS1, VS2, SI1, SI2, I1\n",
    "df[\"clarity\"] = df[\"clarity\"].replace({\"I1\": 1, \"VVS1\": 2, \"SI2\": 3, \"SI1\": 4, \"IF\": 5, \"VS1\":6, \"VVS2\":7, \"VS2\":8})"
   ]
  },
  {
   "source": [
    "## 2. Defining X and y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   carat  cut  color  clarity  depth  table     x     y     z  price\n",
       "0   1.21    5      3        8   63.0   57.0  6.73  6.70  4.23   6134\n",
       "1   0.28    3      7        7   64.0   56.0  4.14  4.17  2.66    532\n",
       "2   0.42    4      5        6   61.2   58.0  4.86  4.82  2.96   1103\n",
       "3   0.26    5      3        5   61.1   57.0  4.16  4.12  2.53    600\n",
       "4   1.10    2      4        4   63.4   57.0  6.52  6.55  4.14   4997"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.21</td>\n      <td>5</td>\n      <td>3</td>\n      <td>8</td>\n      <td>63.0</td>\n      <td>57.0</td>\n      <td>6.73</td>\n      <td>6.70</td>\n      <td>4.23</td>\n      <td>6134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.28</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>4.14</td>\n      <td>4.17</td>\n      <td>2.66</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>61.2</td>\n      <td>58.0</td>\n      <td>4.86</td>\n      <td>4.82</td>\n      <td>2.96</td>\n      <td>1103</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>61.1</td>\n      <td>57.0</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>2.53</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.10</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>63.4</td>\n      <td>57.0</td>\n      <td>6.52</td>\n      <td>6.55</td>\n      <td>4.14</td>\n      <td>4997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As cut will be used when training the model, we can ignore the table and depth as this column is based on those two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"price\"], 1)\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40345, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40345,)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "source": [
    "## 3. Dividing X_train, X_test, y_train, y_test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 4)"
   ]
  },
  {
   "source": [
    "## 4. Model selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Ensembling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The estimator Pipeline should be a classifier.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-4218f8cecea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mvoting_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"soft\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         if (self.weights is not None and\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 raise ValueError(\n\u001b[0;32m    242\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[1;32m--> 243\u001b[1;33m                         \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m                     )\n\u001b[0;32m    245\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator Pipeline should be a classifier."
     ]
    }
   ],
   "source": [
    "# Voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "poly_clf = PolynomialRegression()\n",
    "rnd_clf = RandomForestRegressor(n_estimators=100, random_state=4)\n",
    "svr_clf = SVR()\n",
    "cat_clf = CatBoostRegressor(random_state=42)\n",
    "\n",
    "estimators = [(\"poly\", poly_clf), (\"forest\", rnd_clf), (\"svr\", svr_clf), (\"cat\", cat_clf)]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (poly_clf, rnd_clf, svr_clf, cat_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, np.sqrt(mean_squared_error(y_test, predictions)))\n"
   ]
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [RandomForestRegressor(min_samples_split=8,\n",
       "                                                               n_estimators=500,\n",
       "                                                               random_state=4)],\n",
       "                          'classifier__min_samples_leaf': [1, 2, 3],\n",
       "                          'classifier__min_samples_split': [6, 8, 10],\n",
       "                          'classifier__n_estimators': [100, 500],\n",
       "                          'classifier__random_state': [4]}],\n",
       "             scoring='r2')"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"classifier\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "random_forest_params = {\n",
    "    \"classifier\": [RandomForestRegressor()],\n",
    "    \"classifier__random_state\": [4],\n",
    "    \"classifier__n_estimators\": [100,500],\n",
    "    \"classifier__min_samples_split\": [6,8,10],\n",
    "    \"classifier__min_samples_leaf\": [1,2,3]\n",
    "}\n",
    "\n",
    "search_space = [random_forest_params]\n",
    "\n",
    "clf = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  cv = 10,\n",
    "                  scoring = \"r2\",\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best estimator: RandomForestRegressor(min_samples_split=8, n_estimators=500, random_state=4)\n",
      "clf.best_params_ {'classifier': RandomForestRegressor(min_samples_split=8, n_estimators=500, random_state=4), 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 8, 'classifier__n_estimators': 500, 'classifier__random_state': 4}\n",
      "clf.best_score 0.9803516637924055\n",
      "Wall time: 54min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "# View best model\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'model_random_forest_1.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "source": [
    "### Polynominal "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {\n",
    "    \"polynomialfeatures__degree\": np.arange(10),\n",
    "    #\"linearregression__fit_intercept\": [True, False], \n",
    "    #\"linearregression__normalize\": [True, False]\n",
    "}\n",
    "\n",
    "poly_grid = GridSearchCV(PolynomialRegression(), \n",
    "                param_grid, \n",
    "                cv=10, \n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                verbose=1,\n",
    "                n_jobs=-1)\n",
    "\n",
    "clf_poly.fit(X_train, y_train)\n",
    "clf_poly = GridSearchCV(PolynomialRegression(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1810, in transform\n",
      "    XP[:, current_col:current_col + n_features] = X\n",
      "ValueError: could not broadcast input array from shape (25820,7) into shape (25820,0)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1810, in transform\n",
      "    XP[:, current_col:current_col + n_features] = X\n",
      "ValueError: could not broadcast input array from shape (25821,7) into shape (25821,0)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1810, in transform\n",
      "    XP[:, current_col:current_col + n_features] = X\n",
      "ValueError: could not broadcast input array from shape (25821,7) into shape (25821,0)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1810, in transform\n",
      "    XP[:, current_col:current_col + n_features] = X\n",
      "ValueError: could not broadcast input array from shape (25821,7) into shape (25821,0)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1810, in transform\n",
      "    XP[:, current_col:current_col + n_features] = X\n",
      "ValueError: could not broadcast input array from shape (25821,7) into shape (25821,0)\n",
      "\n",
      "  FitFailedWarning)\n",
      "best estimator: LinearRegression()\n",
      "clf.best_params_ {'polynomialfeatures__degree': 1}\n",
      "clf.best_score 0.8784415219930315\n",
      "Wall time: 1h 34s\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [            nan  8.78441522e-01  7.39771368e-01 -2.80885483e+01\n",
      " -4.30649605e+08 -1.25531655e+13 -4.54043698e+18 -1.87074505e+22\n",
      " -1.05972926e+25 -3.85777327e+24]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit grid search\n",
    "best_model_poly = clf_poly.fit(X_train, y_train)\n",
    "# View best model\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(\"clf.best_params_\", clf_poly.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf_poly.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'model_poly_1.sav'\n",
    "pickle.dump(best_model_poly, open(filename, 'wb'))"
   ]
  },
  {
   "source": [
    "### SVR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"classifier\", SVR)\n",
    "])\n",
    "\n",
    "svr_params = {\n",
    "    \"classifier\": [SVR()],\n",
    "    \"classifier__kernel\": (\"linear\", \"rbf\", \"poly\")\n",
    "    #\"classifier__C\": [1, 10, 100, 1000],\n",
    "    \n",
    "}\n",
    "\n",
    "clf_svr = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = svr_params,\n",
    "                  cv = 10,\n",
    "                  verbose=1,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf_svr.fit(X_train, y_train)\n",
    "clf_svr = GridSearchCV(estimator=pipe, param_grid=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best estimator: LinearRegression()\nclf.best_params_ {'classifier': LinearRegression()}\nclf.best_score 0.8784415219930309\nWall time: 56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit grid search\n",
    "best_model_svr = clf_svr.fit(X_train, y_train)\n",
    "# View best model\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(\"clf.best_params_\", clf_svr.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf_svr.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'model_svr_1.sav'\n",
    "pickle.dump(best_model_svr, open(filename, 'wb'))"
   ]
  },
  {
   "source": [
    "### Catboost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "0:\tlearn: 1705.4355993\ttotal: 143ms\tremaining: 429ms\n",
      "1:\tlearn: 1493.3195033\ttotal: 146ms\tremaining: 146ms\n",
      "2:\tlearn: 1377.5186870\ttotal: 149ms\tremaining: 49.5ms\n",
      "3:\tlearn: 1291.8814477\ttotal: 151ms\tremaining: 0us\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        <catboost.core.CatBoostRegressor object at 0x00000236C9DE5148>)]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier': [<catboost.core.CatBoostRegressor object at 0x00000236C9DE5348>],\n",
       "                         'classifier__depth': [2, 3],\n",
       "                         'classifier__iterations': [2, 4],\n",
       "                         'classifier__learning_rate': [1, 2]},\n",
       "             verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"classifier\", CatBoostRegressor())\n",
    "])\n",
    "\n",
    "catboost_params = {\n",
    "    \"classifier\": [CatBoostRegressor()],\n",
    "    \"classifier__iterations\": [2, 4],\n",
    "    \"classifier__depth\": [2,3],\n",
    "    \"classifier__learning_rate\": [1,2]\n",
    "\n",
    "}\n",
    "                \n",
    "clf_cat = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = catboost_params,\n",
    "                  cv = 10,\n",
    "                  verbose=1,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf_cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "0:\tlearn: 1705.4355993\ttotal: 16.9ms\tremaining: 50.7ms\n",
      "1:\tlearn: 1493.3195033\ttotal: 19.9ms\tremaining: 19.9ms\n",
      "2:\tlearn: 1377.5186870\ttotal: 23.1ms\tremaining: 7.71ms\n",
      "3:\tlearn: 1291.8814477\ttotal: 26.2ms\tremaining: 0us\n",
      "best estimator: LinearRegression()\n",
      "clf.best_params_ {'classifier': <catboost.core.CatBoostRegressor object at 0x00000236C9DE5348>, 'classifier__depth': 3, 'classifier__iterations': 4, 'classifier__learning_rate': 1}\n",
      "clf.best_score 0.9080833704257048\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit grid search\n",
    "best_model_cat = clf_cat.fit(X_train, y_train)\n",
    "# View best model\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(\"clf.best_params_\", clf_cat.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf_cat.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'model_cat_1.sav'\n",
    "pickle.dump(best_model_cat, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model with the best score is RandomForest, so we find its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_random_forest_1.sav\",\"rb\") as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 5. Predictions with X_test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 806.50372157 8600.00738311 1200.35565807 ... 3209.63049135 1098.53669906\n  733.32505205]\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 6. MAE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "554.7035419623857"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 7. Train the model with all available data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z\n",
       "0   0.30      Ideal     H     SI2   60.0   56.0  4.41  4.43  2.65\n",
       "1   0.34      Ideal     D      IF   62.1   57.0  4.52  4.46  2.79\n",
       "2   1.57  Very Good     I     VS2   60.3   58.0  7.58  7.55  4.56\n",
       "3   0.31      Ideal     H     VS2   61.8   57.0  4.32  4.36  2.68\n",
       "4   1.51       Good     I    VVS1   64.0   60.0  7.26  7.21  4.63"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.30</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>SI2</td>\n      <td>60.0</td>\n      <td>56.0</td>\n      <td>4.41</td>\n      <td>4.43</td>\n      <td>2.65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.34</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>IF</td>\n      <td>62.1</td>\n      <td>57.0</td>\n      <td>4.52</td>\n      <td>4.46</td>\n      <td>2.79</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.57</td>\n      <td>Very Good</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>60.3</td>\n      <td>58.0</td>\n      <td>7.58</td>\n      <td>7.55</td>\n      <td>4.56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.31</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>61.8</td>\n      <td>57.0</td>\n      <td>4.32</td>\n      <td>4.36</td>\n      <td>2.68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.51</td>\n      <td>Good</td>\n      <td>I</td>\n      <td>VVS1</td>\n      <td>64.0</td>\n      <td>60.0</td>\n      <td>7.26</td>\n      <td>7.21</td>\n      <td>4.63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "X_pred = pd.read_csv(\"data/diamonds_test.csv\", index_col = 0)\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same transformations than before to X_pred are carried out\n",
    "\n",
    "X_pred[\"cut\"] = X_pred[\"cut\"].replace({\"Ideal\": 5, \"Premium\": 4, \"Very Good\": 3, \"Good\": 2, \"Fair\": 1})\n",
    "\n",
    "X_pred[\"cut\"] = X_pred[\"cut\"]*2\n",
    "\n",
    "X_pred[\"color\"] = X_pred[\"color\"].replace({\"D\": 13, \"E\": 9, \"F\": 8, \"G\": 4, \"H\": 3, \"I\":2, \"J\":1})\n",
    "\n",
    "X_pred[\"clarity\"] = X_pred[\"clarity\"].replace({\"I1\": 1, \"VVS1\": 2, \"SI2\": 3, \"SI1\": 4, \"IF\": 5, \"VS1\":6, \"VVS2\":7, \"VS2\":8})\n",
    "\n",
    "X_pred = X_pred.drop([\"depth\", \"table\"], 1)"
   ]
  },
  {
   "source": [
    "## 8. Prediction with all data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 7786.07089318,  5735.87015654, 16954.72889085, ...,\n",
       "       19464.847141  , 14022.0573367 ,  9946.39476437])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "predictions_submit = best_model.predict(X_pred)\n",
    "predictions_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## **Submission to Kaggle**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  price\n",
       "0   0  12132\n",
       "1   1  11786\n",
       "2   2  14684\n",
       "3   3  15425\n",
       "4   4   6724"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>12132</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14684</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15425</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6724</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id         price\n",
       "0          0   7786.070893\n",
       "1          1   5735.870157\n",
       "2          2  16954.728891\n",
       "3          3   8971.866832\n",
       "4          4  11586.665944\n",
       "...      ...           ...\n",
       "13444  13444  12057.971201\n",
       "13445  13445   6602.209372\n",
       "13446  13446  19464.847141\n",
       "13447  13447  14022.057337\n",
       "13448  13448   9946.394764\n",
       "\n",
       "[13449 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7786.070893</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5735.870157</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>16954.728891</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8971.866832</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11586.665944</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13444</th>\n      <td>13444</td>\n      <td>12057.971201</td>\n    </tr>\n    <tr>\n      <th>13445</th>\n      <td>13445</td>\n      <td>6602.209372</td>\n    </tr>\n    <tr>\n      <th>13446</th>\n      <td>13446</td>\n      <td>19464.847141</td>\n    </tr>\n    <tr>\n      <th>13447</th>\n      <td>13447</td>\n      <td>14022.057337</td>\n    </tr>\n    <tr>\n      <th>13448</th>\n      <td>13448</td>\n      <td>9946.394764</td>\n    </tr>\n  </tbody>\n</table>\n<p>13449 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"id\": range(len(predictions_submit)), \"price\": predictions_submit})\n",
    "submission"
   ]
  },
  {
   "source": [
    "## 5. PÃ¡sale el CHEQUEATOR para comprobar que efectivamente estÃ¡ listo para subir a Kaggle.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta funciÃ³n se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es asÃ­, se guardarÃ¡ el dataframe en un `csv` y estarÃ¡ listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aÃºn no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. TambiÃ©n tÃº.\n",
    "    \"\"\"\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                submission.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que despuÃ©s de todo este notebook hayas hecho algÃºn cambio en las filas de `diamonds_test.csv`. Lloro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}