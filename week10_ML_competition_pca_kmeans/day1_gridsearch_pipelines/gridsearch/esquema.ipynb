{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Datos (clasification / regresión)\n",
    "1.1 Clasification: Logistic Regression, SVC, Knn, Decision Tree, Random Forest Clasificator\n",
    "1.2 Regression: Linear Regression, Polinómica (non-linear regression), SVR, Decision Tree Regressor, Random Forest Regressor\n",
    "\n",
    "2. EDA: Data Wrangling:\n",
    "2.1 Webscrapping, API, Json, CSV, BBDD (SQL/NoSQL), WEB\n",
    "2.2 Correlaciones\n",
    "2.3 Feature Engineering (Extracción de características): outliers, regex, NaNs, distribuciones, estandarizar, normalizar, encoding (dummies), duplicados, eliminar columnas no relevantes\n",
    "2.4 Visualizar los datos para entender\n",
    "2.5 Variables agregadas: columnas agregadas (ejem: media de otras columnas nuevas)\n",
    "2.6 Ponderaciones de columnas (dar más peso a una columna)\n",
    "2.7 Eliminar columnas colineales (eliminar una columna que ofrece la misma información que otra)\n",
    "\n",
    "2. Conclusion: Crear el modelo baseline - hacer machine learning sin haber modificado el modelo original primero para luego comparar si mejora/empeora al hacer el EDA. Asi también vemos si estamos quitando información relevante, etc\n",
    "\n",
    "3. Maquetar los datos\n",
    "\n",
    "4. Partir los datos en conjunto de entrenamiento y de test. Elegimos un % de train/test y semilla\n",
    "\n",
    "5. Cross Validation con el objetivo de saber cómo es el comportamiento de mi modelo para mis datos. \n",
    "5.1 Grid ya lo hace, hay que tener cuidado luego que método uso. \n",
    "Si tenemos muchos datos, mejor no entrenarlo, porque va a tardar mucho\n",
    "\n",
    "6. Gridsearch & Pipeline (es un poco feature engineering)\n",
    "(No probar mas de 1 algoritmo a la vez. Una variable con el Gridsearch por cada algoritmo)\n",
    "\n",
    "7. Nos quedamos con el mejor modelo y probamos el score con el conjunto de test. Nos quedamos con el que mejor generalice.  \n",
    "(Gridsearch nos da score con el conjunto de train, ahora tambien deberíamos sacar el score con el conjunto de test)\n",
    "\n",
    "8. Guardamos el modelo (Pickle)\n",
    "\n",
    "9. .fit(X, y) entrenamos con todos los datos y guardamos el modelo entrenado con otro nombre (Pickle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto solo se puede hacer para fit_transform\n",
    "# guardame el modelo cada 1000 pruebas:\n",
    "if i % 1000 == 0:\n",
    "    pickle.dump(model, open(path + filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}