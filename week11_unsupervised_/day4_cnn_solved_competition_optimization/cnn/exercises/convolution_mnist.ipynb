{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataset mnist (tf.keras.datasets.mnist.load_data()), realiza una clasificación usando:\n",
    "\n",
    "1. Una CNN con:\n",
    "    - 1 capa convolutiva con 8 neuronas\n",
    "    - 1 MaxPool quedando las dimensiones de la imagen a la mitad\n",
    "    - 1 dropout 0.25\n",
    "    - 1 Flatten\n",
    "    - 1 dense con 32 neuronas\n",
    "    - 1 dense con 10 (salida)\n",
    "\n",
    "2. Una CNN con:\n",
    "    - 1 capa convolutiva con 8 neuronas\n",
    "    - 1 MaxPool quedando las dimensiones de la imagen a la mitad\n",
    "    - 1 dropout 0.25\n",
    "    - 1 Flatten\n",
    "    - 1 dense con 16 neuronas\n",
    "    - 1 dense con 32 neuronas\n",
    "    - 1 dense con 10 (salida)\n",
    "\n",
    "¿ Cuál ha dado mejor resultado?\n",
    "\n",
    "Para compilar el modelo, usa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',\r\n",
    " #             loss='sparse_categorical_crossentropy',\r\n",
    "  #            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow y tf.keras\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras.layers import Dropout\r\n",
    "\r\n",
    "# Librerias de ayuda\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.mnist\n",
    "#print(keras.datasets.mnist.load_data())\n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape: (60000, 28, 28)\n",
      "train labes shape: (60000,)\n",
      "test images shape: (10000, 28, 28)\n",
      "test labes shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# data analysis\n",
    "print(f\"train images shape: {train_images.shape}\")\n",
    "print(f\"train labes shape: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test images shape: {test_images.shape}\")\n",
    "print(f\"test labes shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization. Pixeles go from 0 to 255\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization to keep all values between 0 to 1 (rather than 0 to 255)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Una CNN con:\n",
    "\n",
    "1 capa convolutiva con 8 neuronas\n",
    "\n",
    "1 MaxPool quedando las dimensiones de la imagen a la mitad\n",
    "\n",
    "1 dropout 0.25\n",
    "\n",
    "1 Flatten\n",
    "\n",
    "1 dense con 32 neuronas\n",
    "\n",
    "1 dense con 10 (salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                43296     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 43,706\n",
      "Trainable params: 43,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\r\n",
    "model = keras.Sequential([\r\n",
    "    keras.layers.Conv2D(filters=8, \r\n",
    "                        kernel_size=(3, 3), \r\n",
    "                        input_shape=(28, 28, 1), \r\n",
    "                        padding=\"valid\"),\r\n",
    "    keras.layers.MaxPooling2D(2, 2),\r\n",
    "    keras.layers.Dropout(0.25),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\r\n",
    "])\r\n",
    "model.summary()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.expand_dims(train_images, axis=-1) \r\n",
    "print(train_images.shape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3083 - accuracy: 0.9102\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1545 - accuracy: 0.9530\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1181 - accuracy: 0.9635\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1022 - accuracy: 0.9683\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0886 - accuracy: 0.9727\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9741\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9766\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0656 - accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9802\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0572 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225e8553288>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0578 - accuracy: 0.9825\n",
      "\n",
      "Test accuracy: 0.9825000166893005\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \r\n",
    "test_images = np.expand_dims(test_images, axis=-1) \r\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Una CNN con:\n",
    "\n",
    "1 capa convolutiva con 8 neuronas\n",
    "\n",
    "1 MaxPool quedando las dimensiones de la imagen a la mitad\n",
    "\n",
    "1 dropout 0.25\n",
    "\n",
    "1 Flatten\n",
    "\n",
    "1 dense con 16 neuronas\n",
    "\n",
    "1 dense con 32 neuronas\n",
    "\n",
    "1 dense con 10 (salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                21648     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 22,602\n",
      "Trainable params: 22,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model\r\n",
    "model_1 = keras.Sequential([\r\n",
    "    keras.layers.Conv2D(filters=8, \r\n",
    "                        kernel_size=(3, 3), \r\n",
    "                        input_shape=(28, 28, 1), \r\n",
    "                        padding=\"valid\"),\r\n",
    "    keras.layers.MaxPooling2D(2, 2),\r\n",
    "    keras.layers.Dropout(0.25),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\r\n",
    "])\r\n",
    "print(model_1.summary())\r\n",
    "\r\n",
    "model_1.compile(optimizer='adam',\r\n",
    "              loss='sparse_categorical_crossentropy',\r\n",
    "              metrics=['accuracy'])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3830 - accuracy: 0.8818\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1946 - accuracy: 0.9405\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1607 - accuracy: 0.9506\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1384 - accuracy: 0.9574\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1218 - accuracy: 0.9631\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1094 - accuracy: 0.9657\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9694\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0907 - accuracy: 0.9715\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225e7f015c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0649 - accuracy: 0.9797\n",
      "\n",
      "Test accuracy: 0.9797000288963318\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \r\n",
    "test_loss_1, test_acc_1 = model_1.evaluate(test_images, test_labels, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first model gives a lost of 0.05776936560869217 and the second 0.06487603485584259. The first model gives an accuracy of 0.9825000166893005 and the second 0.9797000288963318. The first model is more accurate, so an extra dense layer is not required.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first model gives a lost of {test_loss} and the second {test_loss_1}. The first model gives an accuracy of {test_acc} and the second {test_acc_1}. The first model is more accurate, so an extra dense layer is not required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}