{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing import image\r\n",
    "from tensorflow.keras import datasets, layers, models\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from skimage.io import imread\r\n",
    "import cv2\r\n",
    "import pickle\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "import pandas as pd \r\n",
    "\r\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6176 files belonging to 2 classes.\n",
      "Using 4941 files for training.\n",
      "Found 6176 files belonging to 2 classes.\n",
      "Using 1235 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "img_height = 48\r\n",
    "img_width = 48\r\n",
    "\r\n",
    "data_dir = \"train\"\r\n",
    "\r\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "  data_dir,\r\n",
    "  validation_split=0.2,\r\n",
    "  subset=\"training\",\r\n",
    "  seed=123,\r\n",
    "  image_size=(img_height, img_width),\r\n",
    "  batch_size=batch_size)\r\n",
    "\r\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "  data_dir,\r\n",
    "  validation_split=0.2,\r\n",
    "  subset=\"validation\",\r\n",
    "  seed=123,\r\n",
    "  image_size=(img_height, img_width),\r\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'sadness']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.class_names)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
    "from keras.optimizers import Adam\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "img_height = 48\r\n",
    "img_width = 48\r\n",
    "\r\n",
    "base_model = VGG16(input_shape = (img_height, img_width, 3),\r\n",
    "                  include_top=False,    \r\n",
    "                  weights = 'imagenet')\r\n",
    "\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False \r\n",
    "\r\n",
    "    \r\n",
    "##### FULLY CONNECTED LAYER #####\r\n",
    "# creamos una pequeña red al final del modelo para entrenarlo para nuestros datos\r\n",
    "\r\n",
    "# Flatten the output layer to 1 dimension\r\n",
    "x = layers.Flatten()(base_model.output)\r\n",
    "\r\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\r\n",
    "x = layers.Dense(512, activation='relu')(x) \r\n",
    "\r\n",
    "# Add a dropout rate of 0.5\r\n",
    "x = layers.Dropout(0.5)(x)\r\n",
    "x = layers.Dense(512, activation='relu')(x) \r\n",
    "\r\n",
    "# Add a final sigmoid layer for classification\r\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\r\n",
    "\r\n",
    "# Aquí creamos un modelo concatenado, el ya existente y nuestras nuevas capas\r\n",
    "model = tf.keras.models.Model(base_model.input, x)\r\n",
    "\r\n",
    "model.compile(optimizer = \"Adam\", loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "155/155 [==============================] - 23s 146ms/step - loss: 2.3421 - acc: 0.6021 - val_loss: 0.8447 - val_acc: 0.6534\n",
      "Epoch 2/8\n",
      "155/155 [==============================] - 22s 145ms/step - loss: 0.8144 - acc: 0.6659 - val_loss: 0.6284 - val_acc: 0.6858\n",
      "Epoch 3/8\n",
      "155/155 [==============================] - 22s 144ms/step - loss: 0.6244 - acc: 0.7110 - val_loss: 0.6055 - val_acc: 0.6964\n",
      "Epoch 4/8\n",
      "155/155 [==============================] - 23s 148ms/step - loss: 0.5499 - acc: 0.7314 - val_loss: 0.5964 - val_acc: 0.7093\n",
      "Epoch 5/8\n",
      "155/155 [==============================] - 24s 154ms/step - loss: 0.4948 - acc: 0.7543 - val_loss: 0.5884 - val_acc: 0.7158\n",
      "Epoch 6/8\n",
      "155/155 [==============================] - 25s 161ms/step - loss: 0.4704 - acc: 0.7713 - val_loss: 0.5806 - val_acc: 0.7287\n",
      "Epoch 7/8\n",
      "155/155 [==============================] - 24s 155ms/step - loss: 0.4402 - acc: 0.7934 - val_loss: 0.5979 - val_acc: 0.7117\n",
      "Epoch 8/8\n",
      "155/155 [==============================] - 24s 153ms/step - loss: 0.4114 - acc: 0.8079 - val_loss: 0.6185 - val_acc: 0.7158\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_ds,\r\n",
    "                    validation_data = val_ds,\r\n",
    "                    epochs = 8,\r\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 48, 48, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       test/18341.jpg\n",
       "1       test/13176.jpg\n",
       "2       test/23945.jpg\n",
       "3       test/15968.jpg\n",
       "4       test/18382.jpg\n",
       "             ...      \n",
       "4112    test/08966.jpg\n",
       "4113    test/12111.jpg\n",
       "4114    test/16629.jpg\n",
       "4115    test/24322.jpg\n",
       "4116    test/23412.jpg\n",
       "Name: path, Length: 4117, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"test_set.csv\")[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18341</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13176</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23945</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15968</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18382</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_img    label\n",
       "0   18341    happy\n",
       "1   13176    happy\n",
       "2   23945  sadness\n",
       "3   15968    happy\n",
       "4   18382    happy"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir = list(pd.read_csv(\"test_set.csv\")[\"path\"])\r\n",
    "\r\n",
    "images = [tf.keras.preprocessing.image.load_img(filename, target_size=(img_height, img_width)) for filename in list_dir]\r\n",
    "test_ds = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in images])\r\n",
    "test_ds = tf.data.Dataset.from_tensors(test_ds)\r\n",
    "\r\n",
    "predictions = model.predict(test_ds)\r\n",
    "results = np.array([np.max(predictions[i]) for i in range(len(predictions))])\r\n",
    "\r\n",
    "sample = pd.read_csv('test_set.csv')\r\n",
    "id_col = sample['id_img']\r\n",
    "\r\n",
    "submission = pd.DataFrame({'id_img':id_col, 'label':results}, index=range(len(id_col)))\r\n",
    "submission.label = submission.label.apply(lambda x: 1 if x >= 0.5 else 0)\r\n",
    "submission.label = submission.label.apply(lambda x: 'happy' if x == 0 else 'sadness')\r\n",
    "\r\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18341</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13176</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23945</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15968</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18382</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>8966</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>12111</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>16629</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>24322</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>23412</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img    label\n",
       "0      18341  sadness\n",
       "1      13176  sadness\n",
       "2      23945    happy\n",
       "3      15968    happy\n",
       "4      18382    happy\n",
       "...      ...      ...\n",
       "4112    8966  sadness\n",
       "4113   12111  sadness\n",
       "4114   16629  sadness\n",
       "4115   24322  sadness\n",
       "4116   23412    happy\n",
       "\n",
       "[4117 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\r\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\r\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\r\n",
    "    \"\"\"\r\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\r\n",
    "    \r\n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\r\n",
    "    \r\n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\r\n",
    "    \r\n",
    "    Si aún no:\r\n",
    "    - apaga tu ordenador, \r\n",
    "    - date una vuelta, \r\n",
    "    - enciendelo otra vez, \r\n",
    "    - abre este notebook y \r\n",
    "    - leelo todo de nuevo. \r\n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\r\n",
    "    \"\"\"\r\n",
    "    if df_to_submit.shape == sample.shape:\r\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\r\n",
    "            if df_to_submit.id_img.all() == sample.id_img.all():\r\n",
    "                print(\"You're ready to submit!\")\r\n",
    "                submission.to_csv(\"submission.csv\", index = False) #muy importante el index = False\r\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \r\n",
    "                img = Image.open(\"gfg.png\")\r\n",
    "                img.show()   \r\n",
    "            else:\r\n",
    "                print(\"Check the ids and try again\")\r\n",
    "        else:\r\n",
    "            print(\"Check the names of the columns and try again\")\r\n",
    "    else:\r\n",
    "        print(\"Check the number of rows and/or columns and try again\")\r\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're ready to submit!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a2ac9bfa332d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchequeator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-0588a2df21fd>\u001b[0m in \u001b[0;36mchequeator\u001b[1;34m(df_to_submit)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You're ready to submit!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#muy importante el index = False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gfg.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gfg.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}