{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing import image\r\n",
    "from tensorflow.keras import datasets, layers, models\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from skimage.io import imread\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike or None, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9b4f6b8a80ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m   batch_size=batch_size)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, smart_resize)\u001b[0m\n\u001b[0;32m    188\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m       follow_links=follow_links)\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     66\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0msubdirs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike or None, not DataFrame"
     ]
    }
   ],
   "source": [
    "import pandas as pd \r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "img_height = 48\r\n",
    "img_width = 48\r\n",
    "\r\n",
    "data_dir = pd.read_csv(\"train_set.csv\", sep=\";\") \r\n",
    "\r\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "  data_dir,\r\n",
    "  validation_split=0.2,\r\n",
    "  subset=\"training\",\r\n",
    "  seed=123,\r\n",
    "  image_size=(img_height, img_width),\r\n",
    "  batch_size=batch_size)\r\n",
    "\r\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "  data_dir,\r\n",
    "  validation_split=0.2,\r\n",
    "  subset=\"validation\",\r\n",
    "  seed=123,\r\n",
    "  image_size=(img_height, img_width),\r\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
    "\r\n",
    "base_model = VGG16(input_shape = (img_height, img_width, 3),\r\n",
    "                  include_top=False,    # false porque ahora la vamos a entrenar nosotros. No nos cogemos todos los pesos\r\n",
    "                  weights = 'imagenet')\r\n",
    "\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False # el modelo no se entrena, pero ya tiene sus pesos\r\n",
    "\r\n",
    "    \r\n",
    "##### FULLY CONNECTED LAYER #####\r\n",
    "# creamos una pequeña red al final del modelo para entrenarlo para nuestros datos\r\n",
    "\r\n",
    "# Flatten the output layer to 1 dimension\r\n",
    "x = layers.Flatten()(base_model.output)\r\n",
    "\r\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\r\n",
    "x = layers.Dense(512, activation='relu')(x) # esta x se refiere a la de antes\r\n",
    "\r\n",
    "# Add a dropout rate of 0.5\r\n",
    "x = layers.Dropout(0.5)(x)\r\n",
    "\r\n",
    "# Add a final sigmoid layer for classification\r\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\r\n",
    "\r\n",
    "# Aquí creamos un modelo concatenado, el ya existente y nuestras nuevas capas\r\n",
    "model = tf.keras.models.Model(base_model.input, x)\r\n",
    "\r\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "155/155 [==============================] - 22s 142ms/step - loss: 0.3807 - acc: 0.8290 - val_loss: 0.7065 - val_acc: 0.7028\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 23s 145ms/step - loss: 0.3539 - acc: 0.8419 - val_loss: 0.7162 - val_acc: 0.7263\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 23s 148ms/step - loss: 0.3345 - acc: 0.8488 - val_loss: 0.8212 - val_acc: 0.7142\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 21s 138ms/step - loss: 0.3040 - acc: 0.8666 - val_loss: 0.7632 - val_acc: 0.7077\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 22s 144ms/step - loss: 0.2948 - acc: 0.8780 - val_loss: 0.7859 - val_acc: 0.7263\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 23s 147ms/step - loss: 0.2749 - acc: 0.8865 - val_loss: 0.8267 - val_acc: 0.7190\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 23s 149ms/step - loss: 0.2632 - acc: 0.8887 - val_loss: 0.8895 - val_acc: 0.7158\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 23s 151ms/step - loss: 0.2582 - acc: 0.8879 - val_loss: 0.8181 - val_acc: 0.7117\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 23s 150ms/step - loss: 0.2412 - acc: 0.8976 - val_loss: 0.8855 - val_acc: 0.7247\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 23s 147ms/step - loss: 0.2326 - acc: 0.9037 - val_loss: 0.9083 - val_acc: 0.7271\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_ds,\r\n",
    "                    validation_data = val_ds,\r\n",
    "                    epochs = 10,\r\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos primero los datos de entrenamiento\r\n",
    "trainPredict = model.predict(train_ds)\r\n",
    "\r\n",
    "# y luego el de test\r\n",
    "#testPredict = model.predict(test_ds)\r\n",
    "\r\n",
    "# concatenamos antes\r\n",
    "#predicted = np.concatenate((trainPredict,testPredict),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}